Simple-ETL-Customer-Pipeline

Simple ETL Customer Pipeline: A mini data engineering project for cleaning, transforming, and preparing customer data. Includes handling missing values, duplicates, and basic data validation.
ðŸ“Œ Project: Customer Data Cleaning & Transformation
ðŸ“– Overview

This project demonstrates a simple Data Engineering pipeline for customer data.
The dataset is stored in a csv file (tab-separated) and contains customer information (ID, Name, Age, City).
The goal is to clean, transform, and prepare the data for further use (analysis, ML, or storage).
ðŸ”§ Steps in the Pipeline

 Extract Load customer data from .csv file using pandas.

Transform
        Convert column types:
            CustomerID â†’ int64
            Name â†’ string
            Age â†’ Int64 (nullable integer)
            City â†’ string
        Handle missing values (empty Age/City).
        Remove duplicates.
        Normalize text values (fix inconsistent city names, trim whitespaces).
        Validate data (Age range, unique IDs).

Load
        Export the cleaned dataset to CSV.
        Ready to be stored in a database or data warehouse.

        
ðŸ“‚ Files in Repository

customers.csv â†’ raw data file.
    clean_customers.csv â†’ cleaned dataset.
    data_pipeline.ipynb â†’ Python script for ETL pipeline.
    README.md â†’ project description.
